# ğŸ§  AI-Powered Prompt Engineering Microservice with Streamlit UI

## âœ¨ Project Overview

This project is built as part of an AI Internship Assessment. It is a full-stack AI-powered web prototype that:

- Accepts user input via a clean **Streamlit UI**
- Generates two types of AI responses:
  - A **casual/creative** tone
  - A **formal/analytical** tone
- Saves every interaction in a **PostgreSQL** database
- Uses a **FastAPI** backend microservice to handle request processing and persistence
- Supports prompt engineering and response refinement using **OpenAI GPT models**

---

## ğŸš€ Features

- ğŸ¨ Dual-tone AI prompt engineering (casual vs formal)
- ğŸ”Œ FastAPI backend with robust REST endpoints
- ğŸ’¾ PostgreSQL data persistence with timestamp & user ID tracking
- ğŸ“Š Streamlit frontend to display results + past queries
- ğŸ§ª Modular code with unit test hooks (mock-friendly)
- âš™ï¸ `.env` support for API keys and DB credentials
- âœ… One-click deployable to Render or Streamlit Cloud
- ğŸ§± Clean, extendable architecture (backend/frontend separation)

---

## ğŸ§± Architecture

User â†” Streamlit UI â†” FastAPI Backend â†” PostgreSQL Database
â†•
OpenAI API

yaml
Copy
Edit

- **Frontend:** Streamlit  
- **Backend:** FastAPI  
- **Database:** PostgreSQL  
- **LLM:** OpenAI GPT-3.5/4 (can mock or use Hugging Face models)  
- **Testing:** Pytest-ready stubs (prompt logic, routes)

---

## ğŸ§  Prompt Engineering Strategy

### Styles Implemented:
1. **Casual/Creative Style**
   - Fun, friendly, conversational tone
   - Example prompt:  
     ```
     Explain the topic of {query} like you're chatting with a friend over coffee.
     ```
2. **Formal/Analytical Style**
   - Academic, structured explanation
   - Example prompt:  
     ```
     Provide a formal, well-reasoned explanation of {query} as if writing an academic paper.
     ```

ğŸ’¡ _Bonus Tip:_ This structure can be extended with **prompt chaining** (generate â†’ polish â†’ summarize).

---

## ğŸ“‚ Project Structure

â”œâ”€â”€ app/
â”‚ â”œâ”€â”€ main.py # FastAPI app with endpoints
â”‚ â”œâ”€â”€ models.py # SQLAlchemy DB models
â”‚ â”œâ”€â”€ database.py # PostgreSQL engine & session
â”‚ â”œâ”€â”€ prompt_engineering.py # Core AI logic
â”‚ â””â”€â”€ utils.py # UUID, timestamp helpers
â”‚
â”œâ”€â”€ streamlit_app.py # Streamlit frontend app
â”œâ”€â”€ requirements.txt # Python dependencies
â”œâ”€â”€ .env.example # Example environment variables
â”œâ”€â”€ README.md # This file
â””â”€â”€ tests/
â”œâ”€â”€ test_prompt_logic.py
â””â”€â”€ test_api_routes.py

yaml
Copy
Edit

---

## ğŸ”§ Setup Instructions

### 1. Clone the Repo

```bash
git clone https://github.com/your-username/ai-intern-assessment.git
cd ai-intern-assessment
2. Setup Virtual Environment
bash
Copy
Edit
python -m venv venv
source venv/bin/activate  # or venv\Scripts\activate (Windows)
3. Install Dependencies
bash
Copy
Edit
pip install -r requirements.txt
4. Configure .env File
Create a .env file using .env.example:

env
Copy
Edit
OPENAI_API_KEY=your_openai_key
DATABASE_URL=postgresql://user:password@localhost/dbname
5. Run FastAPI Backend
bash
Copy
Edit
uvicorn app.main:app --reload
6. Run Streamlit Frontend
bash
Copy
Edit
streamlit run streamlit_app.py
ğŸ§ª Testing
Run Unit Tests
bash
Copy
Edit
pytest tests/
test_prompt_logic.py â€” tests formatting + mock model outputs

test_api_routes.py â€” endpoint response validation

ğŸ–¥ï¸ API Documentation
POST /generate
json
Copy
Edit
Request:
{
  "user_id": "abc123",
  "query": "What is blockchain?"
}
json
Copy
Edit
Response:
{
  "casual_response": "...",
  "formal_response": "..."
}
GET /history?user_id=abc123
json
Copy
Edit
[
  {
    "query": "What is blockchain?",
    "casual_response": "...",
    "formal_response": "...",
    "timestamp": "2025-05-20T12:34:56"
  },
  ...
]
ğŸ“¦ Deployment Options
âœ… Streamlit Cloud (Frontend Only)
Push repo to GitHub

Deploy at streamlit.io/cloud

Set secrets in app settings (OPENAI_API_KEY, BACKEND_URL)

âœ… Render.com (Full Stack)
Deploy both FastAPI and Streamlit as separate services

Use Renderâ€™s free PostgreSQL add-on or connect external DB

Add environment variables via dashboard

ğŸ§± Future Improvements (Optional Ideas)
Hugging Face fallback model (offline support)

Prompt chaining or multi-turn memory

User auth (JWT or mock)

Docker + CI pipeline

Chat-style threaded UI

ğŸ§¾ License
MIT License â€” use it freely, customize for your own projects or hiring assessments.

ğŸ™Œ Credits
Developed by [Your Name]
AI + Full Stack Developer Intern Candidate
Tech Stack: OpenAI, FastAPI, Streamlit, PostgreSQL, Python

yaml
Copy
Edit

---

Let me know if you'd like:

- A **Dockerized version**
- This published on **GitHub** with proper structure
- Or help converting it into a **hosted live demo**

Ready when you are!
